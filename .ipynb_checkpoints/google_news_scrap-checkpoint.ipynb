{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developer : Seunghwan Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://newssearch.naver.com/search.naver?where=rss&query=%ED%86%A0%EC%8A%A4%EB%9E%A9&field=0&nx_search_query=&nx_and_query=&nx_sub_query=&nx_search_hlquery=&is_dts=0%22,%22%22,true,100)\n",
    "* 이상 네이터 뉴스 RSS 피드\n",
    "\n",
    "* goose3 를 이용한 예제\n",
    " https://junpyopark.github.io/rss_parse/\n",
    "\n",
    "* sqlite 를 이용한 예제\n",
    " https://brunch.co.kr/@moaikim/38\n",
    "\n",
    "* pandas 를 이용한 엑셀 정리 예제\n",
    " https://m.blog.naver.com/pmw9440/221849471131\n",
    "\n",
    "* news rss 정리\n",
    " https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=mindisit&logNo=220402908308\n",
    "\n",
    "* rss 링크 정리를 위한 pickle 예제\n",
    " https://korbillgates.tistory.com/173\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from goose3 import Goose\n",
    "from goose3.text import StopWordsKorean\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "class newsScrap():\n",
    "    def __init__(self): \n",
    "        print(\"Constructor\")\n",
    "        self._title = []\n",
    "    def __del__(self): \n",
    "        print(\"Garbage Collection\")\n",
    "\n",
    "    def exec(self, keyword, day, country, news_room):\n",
    "        print(\"Crawl\")\n",
    "        URL = news_room # you need to override this method\n",
    "        \n",
    "        res = requests.get(URL)\n",
    "        if res.status_code == 200:\n",
    "            datas = feedparser.parse(res.text).entries ## what is entries?\n",
    "            \n",
    "            for data in datas:\n",
    "                self._title.append(data.title)\n",
    "\n",
    "        else:\n",
    "            print(\"No response\")\n",
    "\n",
    "    def setDataFrame(self):\n",
    "        raw_data = {'title' : self._title}\n",
    "        res = pd.DataFrame(raw_data)\n",
    "        file_name = \"./result.csv\"\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        res.to_csv(file_name)\n",
    "\n",
    "\n",
    "\n",
    "class googleScrap(newsScrap):\n",
    "    def __init__(self):\n",
    "        newsScrap.__init__(self)\n",
    "        self._time = []\n",
    "        self._link = []\n",
    "        self._summary = []\n",
    "        self._source = []\n",
    "        self._keyword = []\n",
    "        self._DataFrame = None\n",
    "\n",
    "    def exec(self, keyword, day, country = 'ko'): # Google News Feed parsing method\n",
    "\n",
    "        print ('Google News Cron Start: ' + datetime.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "        URL = 'https://news.google.com/rss/search?q={}+when:{}d'.format(keyword, day)\n",
    "        \n",
    "        if country == 'en':\n",
    "            URL += '&hl=en-NG&gl=NG&ceid=NG:en'\n",
    "        elif country == 'ko':\n",
    "            URL += '&hl=ko&gl=KR&ceid=KR:ko'\n",
    "\n",
    "        res = requests.get(URL)\n",
    "        if res.status_code == 200:\n",
    "            datas = feedparser.parse(res.text).entries\n",
    "            \n",
    "            for data in datas:\n",
    "                self._title.append(data.title)\n",
    "                self._time.append(data.published)\n",
    "                self._source.append(data.source.title)\n",
    "                self._keyword.append(keyword)   \n",
    "                self._link.append(data.link)\n",
    "                try:\n",
    "                    g = Goose({'stopwords_class':StopWordsKorean})\n",
    "                    article = g.extract(url=url)\n",
    "                    self._summary.append(article.cleaned_text[:500])\n",
    "                    # self._summary.append(article.meta_description)\n",
    "                    # self._summary.append(summarize(article.cleaned_text[:1500]))\n",
    "\n",
    "                except:\n",
    "                    self._summary.append(data.title)\n",
    "                    pass\n",
    "                                 \n",
    "        else:\n",
    "            print ('Google Search Error!!')\n",
    "       \n",
    "    def setDataFrame(self):\n",
    "        #print(len(self._title))\n",
    "        #print(len(self._time))\n",
    "        #print(len(self._summarize))\n",
    "        #print(len(self._link))\n",
    "        #print(len(self._source))\n",
    "        #print(len(self._keyword))\n",
    "        raw_data = {\n",
    "            'title' : self._title,\n",
    "            'time' : self._time,\n",
    "            'summarize' : self._summary,\n",
    "            'link' : self._link,\n",
    "            'source' : self._source,\n",
    "            'keyword' : self._keyword\n",
    "        }\n",
    "        self._DataFrame = pd.DataFrame(raw_data)\n",
    "    \n",
    "    def createCSV(self, file_name):\n",
    "        file = './' + file_name + '.csv'\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "        self._DataFrame.to_csv(file, encoding='utf-8-sig')\n",
    "\n",
    "    def createHTML(self, file_name):\n",
    "        file = './' + file_name + '.html'\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "        self._DataFrame.to_html(file, encoding='utf-8-sig') # use (escape=False) if you want to make URL tag in html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor\n",
      "Google News Cron Start: 07/30/2021, 23:08:57\n",
      "Garbage Collection\n"
     ]
    }
   ],
   "source": [
    "today = googleScrap()\n",
    "today.exec('스마트팩토리', 1)\n",
    "today.setDataFrame()\n",
    "today.createHTML('result')\n",
    "del today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
